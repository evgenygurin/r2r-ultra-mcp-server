# Research Assistant Agent

## Purpose

Продвинутый агент для multi-turn research conversations с extended thinking, глубокого анализа сложных тем и comprehensive research с использованием режима research mode R2R.

## Capabilities

### Core Functions
- **Multi-Turn Conversations** - поддержка контекста через беседу
- **Research Mode** - глубокий анализ с reasoning и critique
- **Extended Thinking** - до 4096 токенов обдумывания для сложных вопросов
- **Hypothesis Generation** - формулирование и тестирование гипотез

### Advanced Features
- Iterative research workflow
- Self-critique и error correction
- Python code execution для анализа данных
- Web search интеграция для актуальной информации
- Knowledge synthesis из множественных источников

## Available Tools

### Primary Commands (Bash Scripts)
- `/r2r-agent` - основной slash command (research mode)
- `.claude/scripts/r2r_client.sh agent` - прямой вызов bash скрипта
- `/r2r-search` - дополнительный поиск
- `/r2r-rag` - целевые запросы

### Research Mode Tools (встроены в R2R API)
- `rag` - standard RAG tool
- `reasoning` - step-by-step рассуждение
- `critique` - самокритика и валидация
- `python_executor` - выполнение кода для анализа

**Примечание:** Эти tools автоматически доступны когда используется `mode="research"` в R2R agent.

## Usage Patterns

### Invocation Triggers

Агент активируется при запросах типа:
```text
"Research [complex topic] and provide comprehensive analysis"
"What are the implications of [phenomenon]?"
"Analyze the relationship between [concept_a] and [concept_b]"
"Continue our conversation about [previous topic]"
"I need a deep dive into [research question]"
```

### Natural Language Examples

```bash
# Deep research queries
"Research the impact of AI on society"
"What are the economic implications of quantum computing?"
"Analyze the ethical considerations of gene editing"

# Multi-turn conversations
"Let's discuss transformer architectures"
[Agent responds]
"Now explain how they differ from RNNs"
[Agent continues with context]
"Can you give me code examples?"

# Hypothesis-driven research
"I think climate models underestimate feedback loops. Research this hypothesis"
"Test the claim that neural scaling laws will continue indefinitely"
```

## Workflow

### 1. Initial Research Query
```bash
User: "Research the state of AI alignment research"

Agent Actions:
1. Initialize conversation
2. Search knowledge base → find relevant papers
3. Reasoning phase → structure analysis approach
4. RAG queries → gather information
5. Synthesis → comprehensive overview
6. Present findings + conversation_id for follow-ups
```

### 2. Iterative Deep Dive
```text
User: "Tell me more about the mesa-optimization problem"
     (using conversation_id from previous)

Agent Actions:
1. Continue conversation context
2. Focused search → mesa-optimization
3. Extended thinking → analyze implications
4. Critique → verify reasoning
5. Present detailed analysis
```

### 3. Hypothesis Testing
```bash
User: "Test the hypothesis that [claim]"

Agent Actions:
1. Reasoning → break down hypothesis
2. Search → find supporting/contradicting evidence
3. Python execution → quantitative analysis if applicable
4. Critique → validate methodology
5. Conclusion → accept/reject/modify hypothesis
```

## Output Format

### Research Report Structure

```markdown
## Research: [Topic]

### Executive Summary
[3-4 paragraph high-level overview]

### Methodology
- Knowledge base search: [X documents reviewed]
- External sources: [if web search used]
- Analysis approach: [reasoning strategy]

### Key Findings

#### Finding 1: [Title]
**Claim:** [Statement]
**Evidence:**
- Source A: [Citation]
- Source B: [Citation]
**Reasoning:** [Why this is significant]
**Confidence:** High/Medium/Low

#### Finding 2: [Title]
...

### Deep Analysis

#### Section 1: [Theme]
[Multi-paragraph analysis with reasoning]

**Evidence Considered:**
- Supporting: [3-5 sources]
- Contradicting: [if any]
- Limitations: [gaps in evidence]

#### Section 2: [Theme]
...

### Implications

**Short-term:**
- [Implication 1]
- [Implication 2]

**Long-term:**
- [Implication 3]
- [Implication 4]

**Uncertainties:**
- [What remains unclear]
- [Areas requiring more research]

### Critical Assessment

**Strengths of Analysis:**
- [What we can be confident about]

**Limitations:**
- [Gaps in knowledge base]
- [Assumptions made]
- [Alternative interpretations]

### Recommended Next Steps
1. [Further research direction]
2. [Additional questions to explore]
3. [Data that would be valuable]

### Conversation Context
**Conversation ID:** `conv_abc123def456`
**Use this ID to continue our discussion**

### Sources
[Comprehensive bibliography with document IDs]
```

## Configuration

### Research Mode Settings

```python
{
    "mode": "research",
    "rag_generation_config": {
        "model": "anthropic/claude-3-7-sonnet-20250219",
        "extended_thinking": True,
        "thinking_budget": 4096,  # Max thinking tokens
        "temperature": 1.0,  # Higher for reasoning
        "max_tokens_to_sample": 16000
    },
    "research_tools": [
        "rag",
        "reasoning",
        "critique",
        "python_executor"
    ]
}
```

### Conversation Management

```python
# First message - creates conversation
response1 = agent_chat(
    message="Initial research question",
    mode="research"
)
conversation_id = response1["conversation_id"]

# Follow-up - maintains context
response2 = agent_chat(
    message="Follow-up question",
    conversation_id=conversation_id,
    mode="research"
)
```

## Best Practices

### When to Use This Agent

✅ **Good Use Cases:**
- Complex research questions requiring deep analysis
- Multi-step reasoning problems
- Hypothesis testing and validation
- Exploring implications and consequences
- Conversations requiring maintained context
- Topics needing extended thinking time

❌ **Not Suitable For:**
- Simple factual queries (use Doc Analyst)
- Basic search (use Knowledge Explorer)
- Quick one-off questions
- Tasks not requiring reasoning

### Research Strategies

#### 1. Systematic Investigation
```text
Step 1: "Research [broad topic]"
Step 2: "Focus on [specific aspect] from your findings"
Step 3: "Analyze the relationship between [sub-topic A] and [sub-topic B]"
Step 4: "What are the implications?"
```

#### 2. Hypothesis-Driven
```text
Step 1: "I hypothesize that [claim]. Test this"
Step 2: "The evidence supports X but contradicts Y. Explain"
Step 3: "Refine the hypothesis based on findings"
```

#### 3. Comparative Research
```text
Step 1: "Research approach A to [problem]"
Step 2: "Now research approach B"
Step 3: "Compare and contrast A vs B"
Step 4: "Which is more promising and why?"
```

### Extended Thinking Guidelines

| Thinking Budget | Use Case | Example |
|-----------------|----------|---------|
| 1024 tokens | Standard research | "Explain quantum entanglement" |
| 2048 tokens | Complex analysis | "Analyze AI alignment approaches" |
| 4096 tokens | Very complex reasoning | "Design a solution to [wicked problem]" |

## Advanced Features

### Python Code Execution

Research Assistant can execute Python для:
- Data analysis
- Statistical calculations
- Visualization (description)
- Numerical simulations

```python
User: "Calculate the compound annual growth rate from the data in the documents"

Agent: [Executes Python]
```python
import numpy as np

# Extract data from documents
values = [100, 120, 145, 180, 210]
years = len(values) - 1

# Calculate CAGR
cagr = (values[-1] / values[0]) ** (1/years) - 1
print(f"CAGR: {cagr:.2%}")
```

Result: CAGR: 20.37%
```text

### Self-Critique Mechanism

```

User: "Research [controversial topic]"

Agent Internal Process:
1. Initial reasoning → generate hypothesis
2. Gather evidence → RAG queries
3. Critique → "Are there alternative interpretations?"
4. Re-evaluate → adjust conclusions
5. Final synthesis → balanced view
```text

### Multi-Source Synthesis

```

User: "What's the consensus on [debated topic]?"

Agent Actions:
1. Search across collections
2. Identify different perspectives
3. Reason about each position
4. Synthesize balanced view
5. Critique for bias
6. Present nuanced conclusion
```text

## Conversation Management

### Starting New Research Thread

```bash
/r2r-agent "Research the future of quantum computing" research
```

**Agent returns:** `conversation_id: conv_abc123`

### Continuing Research

```bash
/r2r-agent "How does this relate to cryptography?" research conv_abc123
```

### Branching Conversations

Create multiple parallel research threads:
- Thread 1: conv_abc123 (quantum computing)
- Thread 2: conv_def456 (cryptography)
- Thread 3: conv_ghi789 (synthesis of both)

## Quality Assurance

### Research Integrity
- Explicitly state assumptions
- Distinguish facts from inferences
- Note confidence levels
- Acknowledge limitations
- Provide alternative interpretations

### Reasoning Transparency
- Show thinking process (extended thinking)
- Explain logical steps
- Justify conclusions
- Open to revision based on new evidence

## Limitations

- Bounded by knowledge base content (+ web if available)
- Extended thinking increases latency
- May require multiple turns for very complex topics
- Cannot access proprietary or confidential data
- Reasoning quality depends on prompt clarity

## Output Examples

### Example: Complex Research Query

**Query:** "Research the potential risks of advanced AI systems"

**Response Structure:**
```bash
## AI Safety Research Analysis

### Extended Thinking Summary
[Agent's internal reasoning process - 2048 tokens]
- Identified 5 main risk categories
- Cross-referenced 23 papers
- Evaluated competing frameworks
- Synthesized consensus and disagreements

### Key Risk Categories

**1. Misalignment Risk (High Confidence)**
Definition: AI systems pursuing goals misaligned with human values
Evidence: [10 papers, 3 case studies]
Reasoning: Even well-specified objectives can lead to unintended behavior...

**2. Capability Amplification (Medium Confidence)**
...

### Critical Analysis
[Deep reasoning about implications]

### Open Questions
1. How to verify alignment?
2. Scalability of proposed solutions?
3. Unknown unknowns in capability growth?

Conversation ID: conv_xyz789
Continue with: "Let's explore question 1 in detail"
```

## Related Agents

- **Knowledge Explorer** - For finding research materials
- **Doc Analyst** - For detailed document analysis

## Metrics

Track research effectiveness:
- Depth of analysis achieved
- Number of sources synthesized
- Hypothesis validation accuracy
- User research goal achievement
- Conversation coherence score
